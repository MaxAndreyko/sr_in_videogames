{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from basicsrexamples.data.example_dataset import SRDataset\n",
    "\n",
    "opt_path = \"../options/example_option.yml\"\n",
    "with open(opt_path, \"r\") as f:\n",
    "    opt = yaml.safe_load(f)\n",
    "ds = SRDataset(opt[\"datasets\"][\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lq': tensor([[[0.0471, 0.0510, 0.0549,  ..., 0.6196, 0.6118, 0.6118],\n",
       "          [0.0353, 0.0353, 0.0392,  ..., 0.6157, 0.6118, 0.6039],\n",
       "          [0.0314, 0.0275, 0.0314,  ..., 0.6118, 0.6118, 0.6039],\n",
       "          ...,\n",
       "          [0.4863, 0.3647, 0.2078,  ..., 0.6588, 0.6510, 0.6392],\n",
       "          [0.2863, 0.2588, 0.1020,  ..., 0.6627, 0.6549, 0.6431],\n",
       "          [0.1529, 0.0902, 0.0902,  ..., 0.6627, 0.6549, 0.6471]],\n",
       " \n",
       "         [[0.0549, 0.0588, 0.0588,  ..., 0.6314, 0.6235, 0.6235],\n",
       "          [0.0431, 0.0431, 0.0471,  ..., 0.6275, 0.6275, 0.6196],\n",
       "          [0.0353, 0.0314, 0.0392,  ..., 0.6235, 0.6235, 0.6196],\n",
       "          ...,\n",
       "          [0.5412, 0.3686, 0.1922,  ..., 0.6706, 0.6667, 0.6549],\n",
       "          [0.2471, 0.1922, 0.0941,  ..., 0.6706, 0.6627, 0.6588],\n",
       "          [0.1490, 0.0824, 0.0863,  ..., 0.6706, 0.6667, 0.6588]],\n",
       " \n",
       "         [[0.0588, 0.0588, 0.0549,  ..., 0.7765, 0.7765, 0.7765],\n",
       "          [0.0471, 0.0471, 0.0510,  ..., 0.7765, 0.7765, 0.7725],\n",
       "          [0.0353, 0.0392, 0.0431,  ..., 0.7765, 0.7765, 0.7765],\n",
       "          ...,\n",
       "          [0.5765, 0.3490, 0.1373,  ..., 0.8078, 0.8039, 0.8000],\n",
       "          [0.1922, 0.1255, 0.0510,  ..., 0.8039, 0.8000, 0.8000],\n",
       "          [0.1020, 0.0471, 0.0431,  ..., 0.8039, 0.8000, 0.8000]]]),\n",
       " 'gt': tensor([[[0.0471, 0.0471, 0.0471,  ..., 0.6157, 0.6196, 0.6196],\n",
       "          [0.0392, 0.0431, 0.0510,  ..., 0.6157, 0.6196, 0.6118],\n",
       "          [0.0431, 0.0471, 0.0510,  ..., 0.6157, 0.6196, 0.6039],\n",
       "          ...,\n",
       "          [0.1608, 0.3137, 0.3176,  ..., 0.6510, 0.6471, 0.6510],\n",
       "          [0.1569, 0.2471, 0.1882,  ..., 0.6549, 0.6510, 0.6471],\n",
       "          [0.1059, 0.1176, 0.1059,  ..., 0.6549, 0.6431, 0.6431]],\n",
       " \n",
       "         [[0.0510, 0.0510, 0.0549,  ..., 0.6275, 0.6314, 0.6314],\n",
       "          [0.0510, 0.0549, 0.0588,  ..., 0.6314, 0.6235, 0.6196],\n",
       "          [0.0471, 0.0549, 0.0627,  ..., 0.6275, 0.6314, 0.6196],\n",
       "          ...,\n",
       "          [0.2431, 0.2941, 0.1922,  ..., 0.6588, 0.6588, 0.6627],\n",
       "          [0.1216, 0.1216, 0.0941,  ..., 0.6667, 0.6667, 0.6627],\n",
       "          [0.1020, 0.1216, 0.1216,  ..., 0.6588, 0.6549, 0.6588]],\n",
       " \n",
       "         [[0.0588, 0.0667, 0.0667,  ..., 0.7804, 0.7804, 0.7804],\n",
       "          [0.0627, 0.0627, 0.0667,  ..., 0.7804, 0.7765, 0.7765],\n",
       "          [0.0549, 0.0627, 0.0667,  ..., 0.7804, 0.7765, 0.7686],\n",
       "          ...,\n",
       "          [0.1020, 0.1333, 0.1020,  ..., 0.8039, 0.8000, 0.8039],\n",
       "          [0.0706, 0.0863, 0.0667,  ..., 0.8039, 0.8039, 0.8118],\n",
       "          [0.0549, 0.0706, 0.0588,  ..., 0.7961, 0.7961, 0.8000]]]),\n",
       " 'lq_path': '../datasets/ExampleDataset/lr/7.png',\n",
       " 'gt_path': '../datasets/ExampleDataset/hr/7.png'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disable distributed.\n",
      "Path already exists. Rename it to /home/maka/Projects/mag_super_resolution/experiments/debug_ESRGAN_train_archived_20240813_164446\n",
      "2024-08-13 16:44:46,429 INFO: \n",
      "                ____                _       _____  ____\n",
      "               / __ ) ____ _ _____ (_)_____/ ___/ / __ \\\n",
      "              / __  |/ __ `// ___// // ___/\\__ \\ / /_/ /\n",
      "             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/\n",
      "            /_____/ \\__,_//____//_/ \\___//____//_/ |_|\n",
      "     ______                   __   __                 __      __\n",
      "    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /\n",
      "   / / __ / __ \\ / __ \\ / __  /  / /   / / / // ___// //_/  / /\n",
      "  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/\n",
      "  \\____/ \\____/ \\____/ \\____/  /_____/\\____/ \\___//_/|_|  (_)\n",
      "    \n",
      "Version Information: \n",
      "\tBasicSR: 1.4.2\n",
      "\tPyTorch: 2.4.0+cu121\n",
      "\tTorchVision: 0.19.0+cu121\n",
      "2024-08-13 16:44:46,429 INFO: \n",
      "  name: debug_ESRGAN_train\n",
      "  model_type: ESRGANModel\n",
      "  num_gpu: 0\n",
      "  manual_seed: 0\n",
      "  preparation:[\n",
      "    subimages:[\n",
      "      n_thread: 6\n",
      "      compression_level: 9\n",
      "      input_folder: ./datasets/ExampleDataset/hr\n",
      "      save_folder: ./datasets/ExampleDataset/hr_subimages\n",
      "      crop_size: 32\n",
      "      step: 32\n",
      "      thresh_size: 32\n",
      "    ]\n",
      "    split:[\n",
      "      dataroot: ./datasets/ExampleDataset\n",
      "      hq_folder: hr_subimages\n",
      "      lq_folder: lr_subimages\n",
      "      train_txt_name: train\n",
      "      val_txt_name: val\n",
      "      ratio: 0.3\n",
      "      random_state: 42\n",
      "    ]\n",
      "  ]\n",
      "  datasets:[\n",
      "    train:[\n",
      "      phase: train\n",
      "      name: ESRGAN_dataset\n",
      "      type: SRDataset\n",
      "      dataroot: ../datasets/ExampleDataset\n",
      "      hq_folder: hr_subimages\n",
      "      lq_folder: lr_subimages\n",
      "      txt_name: train\n",
      "      io_backend:[\n",
      "        type: disk\n",
      "      ]\n",
      "      hq_size: 32\n",
      "      scale: 4\n",
      "      use_flip: True\n",
      "      use_rot: True\n",
      "      use_shuffle: True\n",
      "      num_worker_per_gpu: 3\n",
      "      batch_size_per_gpu: 16\n",
      "      dataset_enlarge_ratio: 10\n",
      "      prefetch_mode: None\n",
      "    ]\n",
      "    val:[\n",
      "      name: ESRGAN_dataset\n",
      "      type: SRDataset\n",
      "      dataroot: ../datasets/ExampleDataset\n",
      "      hq_folder: hr_subimages\n",
      "      lq_folder: lr_subimages\n",
      "      txt_name: val\n",
      "      io_backend:[\n",
      "        type: disk\n",
      "      ]\n",
      "      hq_size: 32\n",
      "      scale: 4\n",
      "      use_flip: False\n",
      "      use_rot: False\n",
      "      phase: val\n",
      "    ]\n",
      "  ]\n",
      "  network_g:[\n",
      "    type: ESRGAN_G\n",
      "    nchannels: 3\n",
      "    nf: 64\n",
      "    scale: 4\n",
      "  ]\n",
      "  network_d:[\n",
      "    type: ESRGAN_D\n",
      "    nchannels: 3\n",
      "    use_sigmoid: True\n",
      "    hq_size: 32\n",
      "  ]\n",
      "  path:[\n",
      "    pretrain_network_g: None\n",
      "    strict_load_g: True\n",
      "    resume_state: None\n",
      "    experiments_root: /home/maka/Projects/mag_super_resolution/experiments/debug_ESRGAN_train\n",
      "    models: /home/maka/Projects/mag_super_resolution/experiments/debug_ESRGAN_train/models\n",
      "    training_states: /home/maka/Projects/mag_super_resolution/experiments/debug_ESRGAN_train/training_states\n",
      "    log: /home/maka/Projects/mag_super_resolution/experiments/debug_ESRGAN_train\n",
      "    visualization: /home/maka/Projects/mag_super_resolution/experiments/debug_ESRGAN_train/visualization\n",
      "  ]\n",
      "  train:[\n",
      "    optim_g:[\n",
      "      type: Adam\n",
      "      lr: 0.0002\n",
      "      weight_decay: 0\n",
      "      betas: [0.9, 0.99]\n",
      "    ]\n",
      "    optim_d:[\n",
      "      type: Adam\n",
      "      lr: 0.0002\n",
      "      weight_decay: 0\n",
      "      betas: [0.9, 0.99]\n",
      "    ]\n",
      "    scheduler:[\n",
      "      type: MultiStepLR\n",
      "      milestones: [50000]\n",
      "      gamma: 0.5\n",
      "    ]\n",
      "    total_iter: 100\n",
      "    warmup_iter: -1\n",
      "    perceptual_opt:[\n",
      "      type: PerceptualLoss\n",
      "      layer_weights:[\n",
      "        conv5_4: 1.0\n",
      "      ]\n",
      "    ]\n",
      "    pixel_opt:[\n",
      "      type: L1Loss\n",
      "      loss_weight: 1.0\n",
      "    ]\n",
      "    gan_opt:[\n",
      "      type: GANLoss\n",
      "      gan_type: vanilla\n",
      "      loss_weight: 1.0\n",
      "    ]\n",
      "  ]\n",
      "  val:[\n",
      "    val_freq: 8\n",
      "    save_img: False\n",
      "    metrics:[\n",
      "      psnr:[\n",
      "        type: calculate_psnr\n",
      "        crop_border: 4\n",
      "        test_y_channel: False\n",
      "      ]\n",
      "    ]\n",
      "  ]\n",
      "  logger:[\n",
      "    print_freq: 1\n",
      "    save_checkpoint_freq: 8\n",
      "    use_tb_logger: True\n",
      "    wandb:[\n",
      "      project: None\n",
      "      resume_id: None\n",
      "    ]\n",
      "  ]\n",
      "  dist_params:[\n",
      "    backend: nccl\n",
      "    port: 29500\n",
      "  ]\n",
      "  dist: False\n",
      "  rank: 0\n",
      "  world_size: 1\n",
      "  auto_resume: False\n",
      "  is_train: True\n",
      "  root_path: /home/maka/Projects/mag_super_resolution\n",
      "\n",
      "2024-08-13 16:44:46,439 INFO: Dataset [SRDataset] - ESRGAN_dataset is built.\n",
      "2024-08-13 16:44:46,440 INFO: Training statistics:\n",
      "\tNumber of train images: 7168\n",
      "\tDataset enlarge ratio: 10\n",
      "\tBatch size per gpu: 16\n",
      "\tWorld size (gpu number): 1\n",
      "\tRequire iter number per epoch: 4480\n",
      "\tTotal epochs: 1; iters: 100.\n",
      "2024-08-13 16:44:46,444 INFO: Dataset [SRDataset] - ESRGAN_dataset is built.\n",
      "2024-08-13 16:44:46,445 INFO: Number of val images/folders in ESRGAN_dataset: 3072\n",
      "2024-08-13 16:44:46,692 INFO: Network [ESRGAN_G] is created.\n",
      "2024-08-13 16:44:46,693 INFO: Network: ESRGAN_G, with parameters: 114,129\n",
      "2024-08-13 16:44:46,693 INFO: ESRGAN_G(\n",
      "  (conv_first): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (conv_blocks): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (upsampling): ESRGAN_Up(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (conv_upcorr): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (conv_last): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2024-08-13 16:44:46,762 INFO: Network [ESRGAN_D] is created.\n",
      "2024-08-13 16:44:46,762 INFO: Network: ESRGAN_D, with parameters: 4,196,353\n",
      "2024-08-13 16:44:46,762 INFO: ESRGAN_D(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "  (lrelu): LeakyReLU(negative_slope=0.01)\n",
      "  (dense_out): Linear(in_features=1024, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "2024-08-13 16:44:46,762 INFO: Loss [L1Loss] is created.\n",
      "/home/maka/Projects/mag_super_resolution/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/maka/Projects/mag_super_resolution/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "2024-08-13 16:44:47,816 INFO: Loss [PerceptualLoss] is created.\n",
      "2024-08-13 16:44:47,817 INFO: Loss [GANLoss] is created.\n",
      "2024-08-13 16:44:47,817 INFO: Model [ESRGANModel] is created.\n",
      "2024-08-13 16:44:47,889 INFO: Start training from epoch: 0, iter: 0\n",
      "2024-08-13 16:44:47,890 INFO: Setting epoch: 0\n",
      "2024-08-13 16:44:47,890 INFO: Getting training data: 0\n",
      "2024-08-13 16:44:47,984 INFO: Optimizing parameters\n",
      "2024-08-13 16:44:51,383 INFO: [debug..][epoch:  0, iter:       1, lr:(2.000e-04,)] [eta: 0:00:00, time (data): 3.493 (0.094)] l_g_pix: 1.8752e-01 l_g_percep: 2.2956e+00 l_g_gan: 6.9582e-01 l_d_real: 3.4537e-01 l_d_fake: 3.4532e-01 out_d_real: 4.8366e-01 out_d_fake: 4.7852e-01 \n",
      "2024-08-13 16:44:51,386 INFO: Optimizing parameters\n",
      "2024-08-13 16:44:53,962 INFO: [debug..][epoch:  0, iter:       2, lr:(2.000e-04,)] [eta: 0:01:23, time (data): 3.035 (0.048)] l_g_pix: 2.5354e-01 l_g_percep: 2.2372e+00 l_g_gan: 7.3445e-01 l_d_real: 3.2693e-01 l_d_fake: 3.2683e-01 out_d_real: 5.7428e-01 out_d_fake: 4.9359e-01 \n",
      "2024-08-13 16:44:53,964 INFO: Optimizing parameters\n",
      "2024-08-13 16:44:55,964 INFO: [debug..][epoch:  0, iter:       3, lr:(2.000e-04,)] [eta: 0:01:49, time (data): 2.691 (0.033)] l_g_pix: 1.8985e-01 l_g_percep: 2.1957e+00 l_g_gan: 7.7106e-01 l_d_real: 3.1163e-01 l_d_fake: 3.1087e-01 out_d_real: 6.5182e-01 out_d_fake: 5.0327e-01 \n",
      "2024-08-13 16:44:55,968 INFO: Optimizing parameters\n",
      "2024-08-13 16:44:57,978 INFO: [debug..][epoch:  0, iter:       4, lr:(2.000e-04,)] [eta: 0:02:05, time (data): 2.522 (0.026)] l_g_pix: 2.0008e-01 l_g_percep: 2.1750e+00 l_g_gan: 7.9414e-01 l_d_real: 3.0152e-01 l_d_fake: 3.0119e-01 out_d_real: 6.6902e-01 out_d_fake: 4.7759e-01 \n",
      "2024-08-13 16:44:57,981 INFO: Optimizing parameters\n",
      "2024-08-13 16:44:59,947 INFO: [debug..][epoch:  0, iter:       5, lr:(2.000e-04,)] [eta: 0:02:14, time (data): 2.411 (0.021)] l_g_pix: 1.4927e-01 l_g_percep: 1.9309e+00 l_g_gan: 7.5227e-01 l_d_real: 3.1993e-01 l_d_fake: 3.2008e-01 out_d_real: 5.3582e-01 out_d_fake: 4.2356e-01 \n",
      "2024-08-13 16:44:59,948 INFO: Optimizing parameters\n",
      "2024-08-13 16:45:01,893 INFO: [debug..][epoch:  0, iter:       6, lr:(2.000e-04,)] [eta: 0:02:19, time (data): 2.333 (0.018)] l_g_pix: 2.2279e-01 l_g_percep: 1.9036e+00 l_g_gan: 8.7027e-01 l_d_real: 2.7251e-01 l_d_fake: 2.7317e-01 out_d_real: 7.2266e-01 out_d_fake: 3.9806e-01 \n",
      "2024-08-13 16:45:01,897 INFO: Optimizing parameters\n",
      "2024-08-13 16:45:04,103 INFO: [debug..][epoch:  0, iter:       7, lr:(2.000e-04,)] [eta: 0:02:26, time (data): 2.316 (0.016)] l_g_pix: 3.8229e-01 l_g_percep: 2.4597e+00 l_g_gan: 8.5862e-01 l_d_real: 2.7710e-01 l_d_fake: 2.7671e-01 out_d_real: 6.8285e-01 out_d_fake: 3.7804e-01 \n",
      "2024-08-13 16:45:04,107 INFO: Optimizing parameters\n",
      "2024-08-13 16:45:06,144 INFO: [debug..][epoch:  0, iter:       8, lr:(2.000e-04,)] [eta: 0:02:29, time (data): 2.281 (0.014)] l_g_pix: 1.9734e-01 l_g_percep: 1.9223e+00 l_g_gan: 8.9426e-01 l_d_real: 2.6417e-01 l_d_fake: 2.6401e-01 out_d_real: 7.4046e-01 out_d_fake: 3.7438e-01 \n",
      "2024-08-13 16:45:06,145 INFO: Saving models and training states.\n",
      "2024-08-13 16:49:13,990 INFO: Validation ESRGAN_dataset\n",
      "\t # psnr: 16.1952\tBest: 16.1952 @ 8 iter\n",
      "\n",
      "2024-08-13 16:49:13,992 INFO: Optimizing parameters\n",
      "2024-08-13 16:49:16,449 INFO: [debug..][epoch:  0, iter:       9, lr:(2.000e-04,)] [eta: 0:39:45, time (data): 2.301 (0.013)] l_g_pix: 2.6357e-01 l_g_percep: 2.2361e+00 l_g_gan: 9.4026e-01 l_d_real: 2.4852e-01 l_d_fake: 2.4825e-01 out_d_real: 7.4670e-01 out_d_fake: 3.0320e-01 \n",
      "2024-08-13 16:49:16,450 INFO: Optimizing parameters\n",
      "2024-08-13 16:49:18,439 INFO: [debug..][epoch:  0, iter:      10, lr:(2.000e-04,)] [eta: 0:36:00, time (data): 2.270 (0.012)] l_g_pix: 1.9586e-01 l_g_percep: 2.1307e+00 l_g_gan: 9.5047e-01 l_d_real: 2.4492e-01 l_d_fake: 2.4505e-01 out_d_real: 7.5096e-01 out_d_fake: 2.9046e-01 \n",
      "2024-08-13 16:49:18,442 INFO: Optimizing parameters\n",
      "2024-08-13 16:49:20,773 INFO: [debug..][epoch:  0, iter:      11, lr:(2.000e-04,)] [eta: 0:32:55, time (data): 2.276 (0.011)] l_g_pix: 2.8006e-01 l_g_percep: 1.9826e+00 l_g_gan: 1.0745e+00 l_d_real: 2.0973e-01 l_d_fake: 2.0939e-01 out_d_real: 8.5990e-01 out_d_fake: 2.0456e-01 \n",
      "2024-08-13 16:49:20,775 INFO: Optimizing parameters\n",
      "2024-08-13 16:49:23,273 INFO: [debug..][epoch:  0, iter:      12, lr:(2.000e-04,)] [eta: 0:30:19, time (data): 2.294 (0.010)] l_g_pix: 1.8742e-01 l_g_percep: 1.8517e+00 l_g_gan: 1.0346e+00 l_d_real: 2.2043e-01 l_d_fake: 2.2046e-01 out_d_real: 8.0461e-01 out_d_fake: 2.1086e-01 \n",
      "2024-08-13 16:49:23,278 INFO: Optimizing parameters\n",
      "2024-08-13 16:49:26,272 INFO: [debug..][epoch:  0, iter:      13, lr:(2.000e-04,)] [eta: 0:28:08, time (data): 2.348 (0.010)] l_g_pix: 1.7711e-01 l_g_percep: 1.9325e+00 l_g_gan: 9.8999e-01 l_d_real: 2.3295e-01 l_d_fake: 2.3267e-01 out_d_real: 7.1159e-01 out_d_fake: 1.8721e-01 \n",
      "2024-08-13 16:49:26,273 INFO: Optimizing parameters\n",
      "2024-08-13 16:49:28,456 INFO: [debug..][epoch:  0, iter:      14, lr:(2.000e-04,)] [eta: 0:26:10, time (data): 2.336 (0.009)] l_g_pix: 2.4238e-01 l_g_percep: 1.9910e+00 l_g_gan: 1.0766e+00 l_d_real: 2.0996e-01 l_d_fake: 2.0917e-01 out_d_real: 8.5191e-01 out_d_fake: 1.9446e-01 \n",
      "2024-08-13 16:49:28,458 INFO: Optimizing parameters\n",
      "2024-08-13 16:49:31,474 INFO: [debug..][epoch:  0, iter:      15, lr:(2.000e-04,)] [eta: 0:24:30, time (data): 2.382 (0.008)] l_g_pix: 2.5346e-01 l_g_percep: 1.9702e+00 l_g_gan: 1.1104e+00 l_d_real: 2.0082e-01 l_d_fake: 2.0034e-01 out_d_real: 8.5799e-01 out_d_fake: 1.4871e-01 \n",
      "2024-08-13 16:49:31,476 INFO: Optimizing parameters\n",
      "2024-08-13 16:49:34,157 INFO: [debug..][epoch:  0, iter:      16, lr:(2.000e-04,)] [eta: 0:23:00, time (data): 2.401 (0.008)] l_g_pix: 1.9089e-01 l_g_percep: 1.8373e+00 l_g_gan: 1.0419e+00 l_d_real: 2.1820e-01 l_d_fake: 2.1812e-01 out_d_real: 7.6411e-01 out_d_fake: 1.5850e-01 \n",
      "2024-08-13 16:49:34,158 INFO: Saving models and training states.\n"
     ]
    }
   ],
   "source": [
    "!python ../esrgan_for_videogames/train.py -opt ../options/esrgan_option.yml --debug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
